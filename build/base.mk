# auto-generated by build-tools (0.3.72)

SHELL := /bin/bash
.DEFAULT_GOAL := bootstrap

service_name := data-provisioner
docker_registry := rival-docker.jfrog.io
docker_repo ?= rival/$(service_name)
artifactory_docker_repo ?= $(docker_registry)/$(docker_repo)

ifeq ($(shell uname), Darwin)
	is_mac = yes
endif

ifdef JENKINS_URL
	is_jenkins = yes
endif

# Jenkins sets it via an env var
ifneq ("$(wildcard $(HOME)/.pip/pip.conf)","")
	PIP_INDEX_URL ?= $(shell sed -rn "s/^\s*index-url\s*=\s*(\S+)/\1/p" ~/.pip/pip.conf)
endif

# Allow overriding with an environment variable.
build_tools_image ?= $(docker_registry)/rival/build-tools:0.3.72

# If we're working locally, volume in the parent directory to make certain things easier
# (e.g. installing libraries in edit mode, `build-tools clone`). In Jenkins, we won't be
# doing any of that, so restrict to the current working directory.
ifdef is_jenkins
	pwd_volume_string = "$$(pwd)":"$$(pwd)"
else
	pwd_volume_string = "$$(pwd)"/..:"$$(pwd)"/..:cached
endif

# $(call run_container, <image reference>, <command to run in container>, <extra Docker arguments>)
run_container = docker run -i --rm -u $$(id -u):$$(id -g) -v $(pwd_volume_string) -w "$$(pwd)" ${3} ${1} ${2}

# Docker options for using host's AWS credentials. Voluming in ~/.aws is to have access to named profiles when running
# locally. In Jenkins, the volume is unnecessary (but okay) because we're using an EC2 instance profile. The use of
# HOME=/tmp is so that the AWS CLI has write access to ~/.aws (which is /tmp/.aws inside the container), even when
# running as non-root.
standard_aws_options = -e HOME=/tmp -v ~/.aws:/tmp/.aws -e AWS_PROFILE -e AWS_DEFAULT_REGION -e AWS_CONFIG_FILE

# COMPOSE_PROJECT_NAME namespaces the containers set up by docker-compose.
# If it's already specified as an environment variable (as in the Jenkins build pipeline), use that.
# Otherwise, use the project's name. This makes it easier to run tests for two repos on one system,
# which would clash by default, with both docker-compose project names defaulting to "test".
COMPOSE_PROJECT_NAME ?= $(service_name)
compose = COMPOSE_PROJECT_NAME=$(COMPOSE_PROJECT_NAME) docker-compose -f $(compose_file_path) ${1}
compose_run = $(call compose, run --rm -u $$(id -u):$$(id -g) ${3} ${1} ${2})
compose_run_with_volume = $(call compose_run, ${1}, ${2}, -v $(pwd_volume_string) -w "$$(pwd)" ${3})

#--------------------------------------------------------------
# General artifacts
#--------------------------------------------------------------

version-stamp:
	echo "$(newVersion)" > VERSION

# Appends content to an `artifacts.txt` file for publishing to PRs, jenkins, etc
# $(call record_artifact, <repository>, <artifact reference>)
record_artifact = echo $(strip $(1)): $(strip $(2)) >> artifacts.txt

inject-artifacts-writer-aws-profile:
	@echo '[profile artifacts_writer]' > .aws_config
	@echo 'role_arn = arn:aws:iam::741856864206:role/ArtifactsWriter' >> .aws_config
	@echo 'credential_source = Ec2InstanceMetadata' >> .aws_config

#--------------------------------------------------------------
# Deployment bundle (scripts necessary for deploying the artifact)
#--------------------------------------------------------------

deployment_bundle_includes += project.json Makefile build/base.mk

build/deployment-bundle.zip:
	$(call run_container, $(docker_registry)/tools/zip:latest, -r build/deployment-bundle.zip $(deployment_bundle_includes))

#--------------------------------------------------------------
# Artifactory
#--------------------------------------------------------------

ARTIFACTORY_CREDENTIALS := $(shell echo $(PIP_INDEX_URL) | awk -v FS="(https://|@rival)" '{print $$2}')
ARTIFACTORY_USERNAME := $(shell echo $(ARTIFACTORY_CREDENTIALS) | sed -r "s/:.*//g")
ARTIFACTORY_PASSWORD := $(shell echo $(ARTIFACTORY_CREDENTIALS) | sed -r "s/.*://g")

#--------------------------------------------------------------
# Docker artifacts
#--------------------------------------------------------------

docker-push-artifactory:
	docker push $(artifactory_docker_repo):$(newDockerTag)

	$(call record_artifact, docker, $(artifactory_docker_repo):$(newDockerTag))

	if [ "$(tagAsLatest)" = "true" ]; then \
		docker tag $(artifactory_docker_repo):$(newDockerTag) $(artifactory_docker_repo):latest; \
		docker push $(artifactory_docker_repo):latest; \
		$(call record_artifact, docker, $(artifactory_docker_repo):latest); \
	fi

#--------------------------------------------------------------
# PyPI (Python projects, infrastructure dependencies for all projects)
#--------------------------------------------------------------

# Artifactory deduces the package name and version from the bundle
# produced by sdist above.
pypi_upload = docker run -i --rm -v "$$(pwd)":"$$(pwd)" -w "$$(pwd)" \
	$(docker_registry)/tools/twine:1.13.0 \
	upload -u $(ARTIFACTORY_USERNAME) -p $(ARTIFACTORY_PASSWORD) \
	--repository-url "$(strip $(1))" dist/*

publish-infrastructure-version:
	rm -rf build/infrastructure
	mkdir -p build/infrastructure
	touch build/infrastructure/requirements.txt
	-cp requirements/infrastructure.txt build/infrastructure/requirements.txt

# Note that this setup.py gets run during installation also. Initially I tried `install_requires=sys.stdin.read()`
# which worked when packaging but then none of the deps would get installed when installing the package.
# End-of-line comments and blank lines work fine here.
	cd build/infrastructure && \
		echo "import setuptools; setuptools.setup(name='$(service_name)', version='$(newVersion)', install_requires='''$$(cat requirements.txt)''')" \
			> setup.py

	cd build/infrastructure && \
		$(call run_container, $(docker_registry)/official/python:3.6.8-alpine3.9, python setup.py sdist)

# Not echoing the twine command because it contains credentials.
	@cd build/infrastructure && \
		$(call pypi_upload, https://rival.jfrog.io/rival/api/pypi/pypi-infrastructure)

#--------------------------------------------------------------
# Code check
#--------------------------------------------------------------

ensure-clean-checkout:
	[ -z "$$(git status --porcelain)" ] || (echo "The working directory isn't clean. Try running make init locally."; exit 1)

#--------------------------------------------------------------
# Integration tests
#--------------------------------------------------------------

# Convenience method for running a container with some extra options typically passed in by Jenkins when running
# integration tests (see release repo's integration-tests.Jenkinsfile).
run_integration_tests = $(call run_container, \
	$(1), \
	$(2), \
	$(standard_aws_options) -e TEST_ENV -e TF_OUTPUT_PATH -e PROJECT_NAME -e PROJECT_VERSION $(3))

.PHONY: build/tf-output.json

# Example: `make build/tf-output.json env=pinky`
build/tf-output.json:
	rm -rf build/tf-output && mkdir -p build/tf-output
	$(call aws, s3 sync --exclude '*' --include '*-stack/tf_output.json' s3://rival-snapshots/terraform/latest/$(env) build/tf-output/)
	cat build/tf-output/*-stack/tf_output.json | $(call jq, -s add) > build/tf-output.json
	@echo Set: TF_OUTPUT_PATH=$$(pwd)/build/tf-output.json

# Example: $(call aws, s3 cp ...)
aws = $(call run_container, $(docker_registry)/tools/aws:1.16.171, $(1), $(standard_aws_options) $(2))

# Example: cat output.json | $(call jq, -r some.key)
jq = $(call run_container, $(docker_registry)/tools/jq:1.6, $(1), $(2))





docker_base_image = rival-docker.jfrog.io/node:12.6.0-alpine
dependencies_image_tag = dependencies-$(lastword $(subst :, ,$(docker_base_image)))
compose_file_path ?= docker-compose.yml

ARTIFACTORY_CREDENTIALS := $(shell echo $(PIP_INDEX_URL) | awk -v FS="(https://|@rival)" '{print $$2}')

# User cache directories differ between Linux and Mac. This dir is used to mount into docker containers
# for faster yarn operations
ifdef is_mac
    USER_CACHE_DIR := $(HOME)/Library/Caches/Yarn
else
    USER_CACHE_DIR := $(HOME)/.cache/yarn
endif

compile-typescript:
	$(call compose_run, test, yarn rebuild)

shell:
	$(call compose_run, test, bash)

.PHONY: test
test:
	$(call compose_run, test, yarn checkall)

cleanup:
	-$(call compose, down -t 0 --remove-orphans)

#--------------------------------------------------------------
# General dependencies (JavaScript)
#--------------------------------------------------------------

.npmrc:
	@curl -u$(ARTIFACTORY_CREDENTIALS) https://rival.jfrog.io/rival/api/npm/auth > .npmrc
	echo "registry=https://rival.jfrog.io/rival/api/npm/npm/" >> .npmrc

# Build a :dependencies image, which doesn't need to be kept up to date. Its purpose
# is just to get us ~90% of the way to a complete `yarn install` in much less time.
# Not printing the command because the Artifactory credentials are in plain text...
dependencies-image:
	@if [ "$(forceRebuild)" = "true" ] || (! docker pull $(artifactory_docker_repo):$(dependencies_image_tag)); then \
		docker build \
			-f build/dependencies-js.Dockerfile \
			-t $(artifactory_docker_repo):$(dependencies_image_tag) \
			--build-arg ARTIFACTORY_CREDENTIALS=$(ARTIFACTORY_CREDENTIALS) \
			. && \
		docker push $(artifactory_docker_repo):$(dependencies_image_tag); \
	fi

copy-dependencies-from-image: dependencies-image
	rm -rf node_modules/
	docker create --name dependencies-$(service_name)-$(GIT_COMMIT)-temporary $(artifactory_docker_repo):$(dependencies_image_tag)
	docker cp dependencies-$(service_name)-$(GIT_COMMIT)-temporary:/app/node_modules ./node_modules
	docker rm dependencies-$(service_name)-$(GIT_COMMIT)-temporary

# Note that this target name is intentionally referring to the node_modules/ directory,
# so the target will be skipped if the node_modules directory exists. If you want to rebuild
# the node_modules directory from scratch, use `copy-dependencies-from-image`.
#
# If `copy-dependencies-from-image` is listed as a prerequisite, instead of being called
# directly, then `make node_modules` will always do it, regardless of whether the node_modules/ directory
# exists yet.
node_modules:
	$(MAKE) copy-dependencies-from-image

# The mutex is intended to address cache corruption in Jenkins because yarn doesn't handle
# concurrency correctly. https://github.com/yarnpkg/yarn/issues/683
dependencies install-dependencies: .npmrc node_modules
	mkdir -p $(USER_CACHE_DIR)
	$(call run_container, \
		$(artifactory_docker_repo):$(dependencies_image_tag), \
		yarn --mutex "file:$(USER_CACHE_DIR)/.yarn-mutex", \
		-e YARN_CACHE_FOLDER=$(USER_CACHE_DIR) \
		-v $(USER_CACHE_DIR):$(USER_CACHE_DIR):cached)

license-check:
	docker run --rm $(build_tools_image) cat /tmp/build-tools/build_tools/static/license_strategy.json \
		| $(call run_container, $(docker_registry)/tools/license-check-js:latest)

# npm expects a hyphen separator for pre-release versions and cannot parse on `+`
npmVersion := $(shell echo ${newVersion} | sed 's/.dev+/-dev./')
# we have to set a tag on prereleases to prevent it from being automatically installed. It cannot include a valid semver
# so remove the semver portion here, and just keep everything after the `dev.` portion
npmTag := $(shell echo ${newVersion} | sed 's/.*dev.//')

publish-npm: .npmrc
#NO_UPDATE_NOTIFIER=true is used to prevent npm warnings due to the home directory being `/`
	if [ "$(isMaster)" = true ]; then \
		$(call run_container, $(docker_base_image), npm publish,-e NO_UPDATE_NOTIFIER=true); \
	else \
		cat package.json | jq '.version="$(npmVersion)"' > package.json.new; \
		mv package.json.new package.json; \
		$(call run_container, $(docker_base_image), npm publish -f --tag $(npmTag),-e NO_UPDATE_NOTIFIER=true); \
	fi
	$(call record_artifact, npm, $(service_name)@$(npmVersion))



pipeline-dependencies-pre: dependencies-image
pipeline-dependencies: .npmrc copy-dependencies-from-image install-dependencies
pipeline-dependencies-post: license-check compile-typescript
pipeline-test: test
pipeline-test-post: cleanup
pipeline-artifacts: publish-npm



TARGET_MAX_CHAR_NUM := 20

# The help target parses and displays help for targets in the current file.
# "Help" is defined as the last double-pound (##) comment line immediately
# preceding the definition of a target.  Note that this implies you can't write
# multi-line help.  (If a target requires multi-line help, take it as a gentle
# hint that the target could stand some refactoring.)

# Note that if a make-help-preamble.txt file exists at the same level as this
# Makefile, it will be used as the preamble to the information this target
# prints out.

# This target was inspired by this thread:
# https://gist.github.com/prwhite/8168133

## Show help for targets in this Makefile
help: _local-help
	@echo ''
	@echo 'Usage:'
	@echo '  make <target>'
	@echo ''
	@echo 'Targets:'
	@awk '/^[a-zA-Z\-\_0-9%]+:/ { \
	helpMessage = match(lastLine, /^## (.*)/); \
	if (helpMessage) { \
	  helpCommand = substr($$1, 0, index($$1, ":")-1); \
	  helpMessage = substr(lastLine, RSTART + 3, RLENGTH); \
	  printf "  %-$(TARGET_MAX_CHAR_NUM)s %s\n", helpCommand, helpMessage; \
	} \
  } \
  { lastLine = $$0 }' $(MAKEFILE_LIST)

_local-help:
	@preamble=$$(cat make-help-preamble.txt 2> /dev/null); echo "$$preamble"

pipeline-code-check: ensure-clean-checkout
